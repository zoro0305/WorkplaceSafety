#!/usr/bin/env python
# -*-coding:utf-8 -*-
'''
@File    :   company_search.py
@Time    :   2023/03/26 20:04:15
@Author  :   Zoro Chang
'''

import streamlit as st
import pandas as pd
import requests
import re
from bs4 import BeautifulSoup

from Home import background

class company_search():
    def _company_search(self, unit: str):
        ######é•åå‹å‹•æ³•ä»¤ç´€éŒ„
        url1 = "https://announcement.mol.gov.tw/"

        data1 = {
            "UNITNAME": unit
        }
        response = requests.post(url1, data=data1)
        html = response.text

        # ä½¿ç”¨ BeautifulSoup è§£æé é¢å†…å®¹
        soup = BeautifulSoup(html, "html.parser")

        for td in soup.find_all('td', class_='column10'):
            td.extract()

        titles=[]
        for title in soup.find_all(class_="col-xs-12 form-group lawTitle"):
            titles.append(title.text.strip())

        cases =[]
        for case in soup.find_all('tbody'):
            case_list = str(case).replace("\n", "").replace("<br/>", "\n").split("</td>")
            case_list = [_.split(">")[1].strip() for _ in case_list]
            while "<tr" in case_list:
                case_list.remove("<tr")
            while '</tbody' in case_list:
                case_list.remove('</tbody')
            while '<tr class="noDataBorder"' in case_list:
                case_list.remove('<tr class="noDataBorder"')
            cases.append(case_list)

        results=[]
        results.append([cases[0][x:x+8] for x in range(0, len(cases[0]), 8)])
        results.append([cases[1][x:x+7] for x in range(0, len(cases[1]), 7)])
        results.append([cases[2][x:x+8] for x in range(0, len(cases[2]), 8)])

        df1_1 = pd.DataFrame(results[0])
        if not df1_1.empty:
            df1_1[0] = [titles[0] for _ in range(len(df1_1[0]))]
            df1_1 = df1_1.drop(columns=[0,1,3])
            df1_1 = df1_1.rename(columns={2: 'è™•åˆ†æ—¥æœŸ', 4: "äº‹æ¥­å–®ä½åç¨±(è² è²¬äºº) / è‡ªç„¶äººå§“å",
                                        5: "é•æ³•æ³•è¦æ³•æ¢ ", 6: "é•åæ³•è¦å…§å®¹", 7: "ç½°é°é‡‘é¡"})
        df1_2 = pd.DataFrame(results[1])
        if not df1_2.empty:
            df1_2[0] = [titles[1] for _ in range(len(df1_2[0]))]
            df1_2 = df1_2.drop(columns=[0,1,3])
            df1_2 = df1_2.rename(columns={2: 'è™•åˆ†æ—¥æœŸ', 4: "äº‹æ¥­å–®ä½åç¨±(è² è²¬äºº) / è‡ªç„¶äººå§“å",
                                        5: "é•æ³•æ³•è¦æ³•æ¢ ", 6: "é•åæ³•è¦å…§å®¹"})
        df1_3 = pd.DataFrame(results[2])
        if not df1_3.empty:
            df1_3[0] = [titles[2] for _ in range(len(df1_3[0]))]
            df1_3 = df1_3.drop(columns=[0,1,3])
            df1_3 = df1_3.rename(columns={2: 'è™•åˆ†æ—¥æœŸ', 4: "äº‹æ¥­å–®ä½åç¨±(è² è²¬äºº) / è‡ªç„¶äººå§“å",
                                        5: "é•æ³•æ³•è¦æ³•æ¢ ", 6: "é•åæ³•è¦å…§å®¹", 7: "è™•åˆ†é‡‘é¡ï¼æ»¯ç´é‡‘"})

        ######é‡å¤§è·æ¥­ç½å®³ç´€éŒ„
        url2 = "https://pacs.osha.gov.tw/2875/"

        data2 = {
            "q": unit
        }
        response = requests.get(url2, params=data2)
        html = response.text

        # ä½¿ç”¨ BeautifulSoup è§£æé é¢å†…å®¹
        soup = BeautifulSoup(html, "html.parser")

        events = []
        for event in soup.find_all('div', {'class': 'publiclist'}):
            events.append(event.text.strip())

        times, companies, owners, places, addresses, disasters = [], [], [], [], [], []
        for event in events:
            try:
                time_pattern = r'ç™¼ç”Ÿæ—¥æœŸï¼š(.*)\n'
                time_match = re.search(time_pattern, event)
                times.append(time_match.group(1))
            except:
                times.append("")
            try:
                company_pattern = r'äº‹æ¥­å–®ä½ï¼š(.*)\n'
                company_match = re.search(company_pattern, event)
                companies.append(company_match.group(1))
            except:
                companies.append("")
            try:
                owner_pattern = r'æ¥­ä¸»ï¼š(.*)\n'
                owner_match = re.search(owner_pattern, event)
                owners.append(owner_match.group(1))
            except:
                owners.append("")
            try:
                place_pattern = r'å ´æ‰€(.*)\n'
                place_match = re.search(place_pattern, event)
                places.append(place_match.group(1)[5:])
            except:
                places.append("")
            try:
                address_pattern = r'åœ°å€(.*)\n'
                address_match = re.search(address_pattern, event)
                addresses.append(address_match.group(1))
            except:
                addresses.append("")
            try:
                disaster_pattern = r'ç½å®³é¡å‹ï¼š(.*)\n'
                disaster_match = re.search(disaster_pattern, event)
                disasters.append(disaster_match.group(1))
            except:
                disasters.append("")

        df2 = pd.DataFrame()
        if times:
            df2 = pd.DataFrame({'ç™¼ç”Ÿæ—¥æœŸ': times, 'äº‹æ¥­å–®ä½': companies, 'æ¥­ä¸»': owners,
                                'å ´æ‰€(è‚‡ç½è™•)': places, 'åœ°å€': addresses, 'ç½å®³é¡å‹': disasters})

        ######è·æ¥­è¡›ç”Ÿå®‰å…¨ç´€éŒ„
        url3 = "https://pacs.osha.gov.tw/2872/"

        data3 = {
            "q": unit
        }
        response = requests.get(url3, params=data3)
        html = response.text

        # ä½¿ç”¨ BeautifulSoup è§£æé é¢å†…å®¹
        soup = BeautifulSoup(html, "html.parser")

        events = []
        for event in soup.find_all('tr'):
            events.append(event.text.strip())

        events = events[1:]
        years, prizes, companies = [], [], []
        for event in events:
            event = event.split("\n")
            event = [_ for _ in event if _ != ""]
            years.append(event[1])
            prizes.append(event[2])
            companies.append(event[3])

        df3 = pd.DataFrame()
        if years:
            df3 = pd.DataFrame({'ä¼æ¥­åç¨±': companies, 'ç²çå¹´åº¦': years, 'ç²çåç¨±': prizes})

        return df1_1, df1_2, df1_3, df2, df3

    def customized_df(self, df: pd.DataFrame):
        def background_color(val):
            return f'background-color: PapayaWhip'
        return df.style.set_properties(color='Black').applymap(background_color)

    def main(self):
        background("scripts/background.jpg").set_bg_hack()
        st.markdown("<p style='font-family:Courier; font-size: 35px; color: SaddleBrown;'>\
                    <b>è·ç½ã„¨ã„šç†Šç½ğŸ»ï¼è·å ´å®‰å…¨è³‡è¨Šæ”åº•åŠ ï¼</b></p>", unsafe_allow_html=True)
        unit = st.text_input('è¼¸å…¥ è‡ªç„¶äººå§“å/äº‹æ¥­å–®ä½åç¨±: ', "")
        if unit:
            df1_1, df1_2, df1_3, df2, df3 = self._company_search(unit)
            st.markdown("<p style='font-family:Courier; font-size: 15px; color: Peru;'>\
                        <b>è¿‘æœŸé•åå‹å‹•åŸºæº–æ³•ï¼å·¥æœƒæ³•ä¹‹ç´€éŒ„</b></p>", unsafe_allow_html=True)
            if not df1_1.empty:
                st.dataframe(self.customized_df(df1_1))
            else:
                st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                            æŸ¥ç„¡è¿‘æœŸç›¸é—œç´€éŒ„</p>", unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px; color: Peru;'>\
                        <b>è¿‘æœŸé•åæ€§åˆ¥å·¥ä½œå¹³ç­‰æ³•ï¼è·æ¥­å®‰å…¨è¡›ç”Ÿæ³•ï¼å°±æ¥­æœå‹™æ³•ï¼ä¸­é«˜é½¡è€…åŠé«˜é½¡è€…å°±æ¥­ä¿ƒé€²æ³•ä¹‹ç´€éŒ„</b></p>",
                        unsafe_allow_html=True)
            if not df1_2.empty:
                st.dataframe(self.customized_df(df1_2))
            else:
                st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                            æŸ¥ç„¡è¿‘æœŸç›¸é—œç´€éŒ„</p>", unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px; color: Peru;'>\
                        <b>è¿‘æœŸé•åå‹å·¥é€€ä¼‘é‡‘æ¢ä¾‹ï¼å‹å·¥è·æ¥­ç½å®³ä¿éšªåŠä¿è­·æ³•ä¹‹ç´€éŒ„</b></p>", unsafe_allow_html=True)
            if not df1_3.empty:
                st.dataframe(self.customized_df(df1_3))
            else:
                st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                            æŸ¥ç„¡è¿‘æœŸç›¸é—œç´€éŒ„</p>", unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px; color: Peru;'>\
                        <b>è¿‘æœŸé‡å¤§è·æ¥­ç½å®³ä¹‹ç´€éŒ„</b></p>", unsafe_allow_html=True)
            if not df2.empty:
                st.dataframe(self.customized_df(df2))
            else:
                st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                            æŸ¥ç„¡è¿‘æœŸç›¸é—œç´€éŒ„</p>", unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px; color: Peru;'>\
                        <b>è¿‘æœŸè·æ¥­å®‰å…¨è¡›ç”Ÿå„ªè‰¯ä¹‹ç´€éŒ„</b></p>", unsafe_allow_html=True)
            if not df3.empty:
                st.dataframe(self.customized_df(df3))
            else:
                st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                            æŸ¥ç„¡è¿‘æœŸç›¸é—œç´€éŒ„</p>", unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                        <b>ä»¥ä¸Šè¡¨æ ¼å‡ºè‡ªä»¥ä¸‹ç¶²å€çš„é—œéµå­—æœå°‹çµæœï¼š</b></p>", unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                        <a href='https://announcement.mol.gov.tw/'>\
                        é•åå‹å‹•æ³•ä»¤äº‹æ¥­å–®ä½ï¼ˆé›‡ä¸»ï¼‰æŸ¥è©¢ç³»çµ±</a></p>",
                        unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                        <a href='https://pacs.osha.gov.tw/2875/'>\
                        é‡å¤§è·æ¥­ç½å®³å…¬é–‹ç¶²</a></p>",
                        unsafe_allow_html=True)
            st.markdown("<p style='font-family:Courier; font-size: 15px;'>\
                        <a href='https://pacs.osha.gov.tw/2872/'>\
                        è·æ¥­å®‰å…¨è¡›ç”Ÿå“è¶Šç¶²</a></p>",
                        unsafe_allow_html=True)

if __name__ == "__main__":
    web = company_search()
    web.main()
